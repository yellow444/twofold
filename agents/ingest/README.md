# Agent.Ingest

Загрузчик исходных данных Росавиации: парсинг XLS/CSV/PDF/HTML, нормализация и сохранение в хранилище/БД.

## Поддерживаемые форматы

| Формат | Особенности | Ограничения |
| ------ | ----------- | ----------- |
| CSV | Потоковое чтение через Polars Scan API, авто-очистка заголовков и значений. | Файлы >200 МБ читаются в потоковом режиме; поддерживается кодировка UTF-8. |
| XLS/XLSX | Парсинг через `pandas`/`openpyxl` с приведением типов и очисткой служебных строк. | Требуется установленный `openpyxl` (для XLS — `xlrd`). |
| PDF | Попытка чтения через `camelot` → `tabula`; при недоступности библиотек выполняется текстовый парсинг таблиц с объединением страниц. | Для надёжной работы нужен структурированный табличный PDF с прямыми границами; в режиме деградации обрабатываются только строки с явными разделителями. |
| HTML | Извлечение первой таблицы через BeautifulSoup+lxml, поддержка `<meta name="report-tz">`. | Требуется корректная разметка `<table>`/`<thead>`/`<tbody>`; вложенные таблицы не поддерживаются. |

CLI-флаги:

* `python -m app.cli ingest <source>` — запуск пайплайна;
* `--format / -f` — ручной выбор формата (`csv`, `xls`, `xlsx`, `pdf`, `html`);
* `--year / -y` — проставление года партии для downstream-валидаций;
* `--storage-path / -s` — путь для выгрузки в хранилище (при отключённом `--dry-run`);
* `--dataset-version` — переопределение версии датасета в конфигурации;
* `--dry-run` — пропуск записи в хранилище, загрузка и нормализация выполняются полностью.

Ограничения и рекомендации:

* Максимальный объём входного CSV без разбиения — 1 ГБ (стриминг >200 МБ автоматически);
* В PDF желательно использовать однородные таблицы без объединённых ячеек; при ошибках парсинга агент переходит в режим текстового детектора и помечает загрузку как `metadata["degraded"]=True`;
* Для HTML требуется наличие `<table>` c первой строкой заголовков или `thead`; дополнительные таблицы игнорируются.

## Lineage и артефакты

После нормализации пайплайн публикует артефакты в S3/MinIO со структурой `datasets/{year}/{version}/...`:

* `raw.csv` — очищенный исходный CSV, сохранённый без потери заголовков;
* `normalized.parquet` — нормализованный датасет в канонической схеме;
* `lineage.json` — отчёт lineage с контрольной суммой входного файла и счётчиками строк.

В таблице `dataset_version` обновляются поля:

* `status` (`new` → `ingested`),
* `ingested_at` — фактическое время загрузки,
* `checksum` — SHA256 исходного файла,
* `artifacts` — JSONB с URI артефактов (`raw`, `normalized`, `lineage`).

Пример запуска CLI:

```bash
$ python -m app.cli ingest samples/rosaviation_sample.csv --year 2024 --dataset-version 2024-01
INFO  [app.cli] Starting ingest command
INFO  [app.pipeline] Loaded records {'total': 5, 'invalid': 0, 'duplicates': 0}
INFO  [app.pipeline] Finished ingest pipeline {'dataset_version_id': 1, 'checksum': '...'}
```
