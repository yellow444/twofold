# План работ (только open‑source и бесплатно)

## Этап 0. Уточнение требований и метрик

**Задачи:**

* Зафиксировать входные форматы (CSV/XLS/PDF/HTML), целевые метрики: количество полётов, суммарная/средняя длительность, динамика по месяцам, топ‑N регионов.
* Согласовать SLA/производительность (например, обработка партии 10 000 записей ≤ 5 минут), Linux‑окружение, виды экспорта (PNG/JPEG/JSON/CSV/XLSX).
  **Артефакты/DoD:** `requirements.md`, перечень метрик и правил агрегации, пример входных датасетов.

## Этап 1. Репозиторий, лицензии, базовый CI/CD

**Технологии:** GitHub + Actions, Docker.
**Задачи:**

* Моно‑репозиторий: `backend/`, `frontend/`, `agents/`, `infra/`, `docs/`.
* Шаблон лицензии (Apache‑2.0/MIT), `CODEOWNERS`, `CONTRIBUTING.md`.
* GitHub Actions: линт, тесты, сборка Docker‑образов, публикация артефактов.
  **DoD:** статанализ и unit‑тесты проходят; образы собираются и публикуются в GitHub Container Registry.

## Этап 2. Схема данных и хранилища

**Технологии:** PostgreSQL + PostGIS; DuckDB/Parquet (локально); *опционально* ClickHouse для витрин.
**Задачи:**

* DDL: `regions`, `flights_raw`, `flights_norm`, `flights_geo`, `aggregates_year`, `dataset_version`, `quality_report`.
* Индексы (включая GiST для геоколонок); история загрузок и версионирование наборов.
  **DoD:** миграции применяются; геозапросы и агрегаты выполняются в целевое время.

## Этап 3. Импорт и нормализация (Agent.Ingest)

**Технологии:** Python (pandas/polars), PyArrow, DuckDB/Parquet.
**Задачи:**

* Конвертеры форматов (XLS/CSV/PDF/HTML → нормализованный Parquet/CSV).
* Стандартизация дат/времени/часовых поясов; парсинг идентификаторов, координат, длительности.
* Журнал lineage + запись `dataset_version`.
  **DoD:** одна CLI‑команда загружает партию и пишет снапшот в БД и хранилище.

## Этап 4. Контроль качества данных (Agent.Quality)

**Технологии:** Great Expectations (или собственные валидаторы на Python).
**Задачи:**

* Проверки схемы, допустимых диапазонов, уникальности, полноты периодов, выбросов.
* Автоматический отчёт качества с уровнями OK/WARN/FAIL.
  **DoD:** формируется `quality_report` и статус партии; некачественные записи помечены.

## Этап 5. Геопривязка

**Технологии:** PostGIS; официальные shape‑files субъектов РФ; GDAL/Mapshaper (CLI).
**Задачи:**

* Загрузка и обновление шейпов; строгое пересечение точек взлёта/посадки с полигонами субъектов.
* Построение `flights_geo` и обработка граничных случаев (точки на границе/нулевые координаты).
  **DoD:** ≥99% валидных записей имеют корректный субъект РФ.

## Этап 6. Агрегации и витрины

**Технологии:** SQL/PLpgSQL; *опционно* ClickHouse для быстрых срезов.
**Задачи:**

* Материализованные представления/таблицы `aggregates_year` (сумма, средняя/медиана, тренды, сезонность).
* Экспорт агрегатов в JSON/CSV для интеграций.
  **DoD:** стабильные пересчёты на тестовых наборах; сравнимость релизов обеспечена.

## Этап 7. Backend API

**Технологии:** ASP.NET Core (C#) Minimal APIs, EF Core, Swagger/OpenAPI.
**Задачи:**

* Эндпоинты: `/ingest`, `/datasets/{version}`, `/regions`, `/stats`, `/insights`, `/export` (JSON/CSV/XLSX/PNG/JPEG).
* Webhook для интеграций; пагинация, фильтры, сортировки.
  **DoD:** Swagger UI полностью описывает API; Postman‑коллекция в `docs/`.

## Этап 8. Frontend

**Технологии:** React + TypeScript, Vite, Ant Design или MUI, ECharts/Plotly, MapLibre/Leaflet.
**Задачи:**

* Дашборд рейтинга регионов; интерактивная карта; карточка региона с дрилл‑дауном до первички.
* Экспорт CSV/XLSX/PDF; статусы партий и отчётов качества.
  **DoD:** UX‑критерии выполнены (контраст, читаемость, доступность), Lighthouse ≥ 90.

## Этап 9. Инсайты (Agent.Insights)

**Технологии:** Правила + локальные малые LLM (он‑прем) при необходимости.
**Задачи:**

* Короткие человеко‑читабельные пояснения (рост/падение, вклад ТОП‑N, сезонность) без влияния на числа.
  **DoD:** каждый инсайт ссылается на конкретные агрегаты/формулы; воспроизводимость подтверждена.

## Этап 10. Аутентификация и роли

**Технологии:** Keycloak (OpenID Connect), RBAC.
**Задачи:**

* Роли: админ/оператор/читатель; защита API токенами; TLS‑терминация реверс‑прокси (Caddy/Traefik).
  **DoD:** доступ по ролям работает; безопасность проверена базовыми тестами.

## Этап 11. Логи, мониторинг, трассировка

**Технологии:** Prometheus + Grafana, Loki или ELK, Jaeger.
**Задачи:**

* Метрики SLA, длительность ETL, качество данных; алерты.
  **DoD:** дашборды и оповещения развёрнуты; end‑to‑end трассировка запросов.

## Этап 12. Тестирование и производительность

**Технологии:** xUnit/NUnit, Playwright (UI), k6/Locust (нагрузка).
**Задачи:**

* Unit/интеграционные/UI тесты ≥80%; бенчмарк партии (10 000 записей ≤ 5 мин).
  **DoD:** отчёты тестов/покрытия/производительности в CI; артефакты сохраняются.

## Этап 13. Документация и архитектура

**Технологии:** Swagger/OpenAPI, MkDocs или Docusaurus, C4‑диаграммы, Archi (ArchiMate).
**Задачи:**

* Руководство по установке/эксплуатации; архитектурные диаграммы; ограничения/риски; план релиза.
  **DoD:** `docs/` готов; PDF‑версия и презентация; ссылка на работающий прототип.

---

## Карта задач и PR (скелет)

* **PR‑01:** DDL + миграции + `docker-compose` (Postgres+PostGIS, MinIO, Keycloak).
* **PR‑02:** `agents/ingest` (конвертеры, parquet, versioning, CLI).
* **PR‑03:** `agents/quality` (правила, отчёт качества, статусы партий).
* **PR‑04:** Геопривязка (импорт шейпов, PostGIS‑функции, юнит‑тесты).
* **PR‑05:** Агрегации и витрины (матпредставления/таблицы, экспорт JSON/CSV).
* **PR‑06:** Backend API (+Swagger, Postman, генерация PNG/JPEG).
* **PR‑07:** Frontend (карта, рейтинги, карточки, экспорт, состояния партий).
* **PR‑08:** Keycloak RBAC, TLS‑терминация (Caddy/Traefik).
* **PR‑09:** Мониторинг/логи/трейсинг (Prometheus, Grafana, Jaeger, Loki/ELK).
* **PR‑10:** Нагрузочные тесты, отчёт по производительности и SLA.
* **PR‑11:** Документация (MkDocs/Docusaurus, C4/Archi), релизные артефакты.
